{
    "model": "llama3",
    "size": "70B",
    "prefill_stage": {
        "prefill_recent_ratio": 0.2,
        "prefill_decay_ratio": 0.9,
        "prefill_decay_strategy": "cosine",
        "min_context_length": 64,
        "layerwise_downsample_interval": 3,
        "streamingllm_sink_len": 4,
        "distance_weight": 1.2
    },
    "generation_stage": {
        "gen_recent_ratio": 0.2,
        "gen_decay_ratio": 0.1,
        "gen_decay_strategy": "cosine",
        "gen_compress_ratio": 0.9,
        "exceed_length_to_compress": 16
    }
}